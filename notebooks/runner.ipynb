{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complete-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3prl_path= '../s3prl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "characteristic-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(f'{s3prl_path}/transformer/')\n",
    "sys.path.append(f'{s3prl_path}/')\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from torch import nn\n",
    "from model import TransformerModel , TransformerForMaskedAcousticModel , TransformerConfig\n",
    "import transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "patent-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')\n",
    "from model_builder import Wrapper_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.base_transformer_model = None\n",
    "        self.model = None\n",
    "        \n",
    "    def set_transformer_model(self, transformer_config_path, transformer_weights_path):\n",
    "        '''\n",
    "        This Function loads the base transformer model.\n",
    "        \n",
    "        Args:\n",
    "            transformer_config_path : config path(yaml) of the transformer\n",
    "            transformer_weights_path : optional . if given loads the weight as well\n",
    "        \n",
    "        Returns:None\n",
    "        '''\n",
    "\n",
    "        # load base transformer model from config\n",
    "        with open(transformer_config_path, 'r') as file:\n",
    "            config= yaml.load(file, yaml.FullLoader)        \n",
    "\n",
    "        model_config = TransformerConfig(config)\n",
    "        input_dim = config['transformer']['input_dim']\n",
    "        \n",
    "        dr= model_config.downsample_rate\n",
    "        hidden_size = model_config.hidden_size\n",
    "        output_attention= False\n",
    "        \n",
    "        base_transformer_model = TransformerModel(model_config,input_dim,output_attentions=output_attention).to('cpu')\n",
    "\n",
    "        #load weights\n",
    "        if transformer_weights_path:\n",
    "            ckpt = torch.load(transformer_weights_path, map_location='cpu')\n",
    "            base_transformer_model.load_state_dict(ckpt['Transformer'])\n",
    "\n",
    "        self.base_transformer_model = base_transformer_model\n",
    "        \n",
    "    def set_model(self,transformer_config_path, transformer_weights_path=None, ckpt_path=None):\n",
    "        self.set_transformer_model(transformer_config_path, transformer_weights_path)\n",
    "        self.model = Wrapper_Model(self.base_transformer_model)\n",
    "        \n",
    "        if ckpt_path:\n",
    "            ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "            self.model.load_state_dict(ckpt)\n",
    "            \n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "runner= Runner(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dimensional-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_config_path = \"/home/jupyter/rfcx_submission/config/upstream_config.yaml\"\n",
    "transformer_weights_path = '/home/jupyter/rfcx/rfcx/model_weights/mockingjay_mel80_no_delta_cmvn_run4/states-2000.ckpt'\n",
    "\n",
    "runner.set_model(transformer_config_path, transformer_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-channel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-wound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-submission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/rfcx_submission/scripts')\n",
    "\n",
    "import load_mel\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram_to_numpy(spectrogram):\n",
    "    spectrogram = spectrogram.transpose(1, 0)\n",
    "    fig, ax = plt.subplots(figsize=(18, 3))\n",
    "    im = ax.imshow(spectrogram, aspect=\"auto\", origin=\"lower\",cmap='magma')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Channels\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor= Preprocessor(hidden_size =768, dr=1, device=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files= glob.glob('/home/jupyter/rfcx/data/*/*.flac')\n",
    "# audio_files= glob.glob('/home/jupyter/librispeech/LibriSpeech/test-other/1688/142285/*.flac')\n",
    "len(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file= audio_files[-50]\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=32000\n",
    "y,sr= load_mel.load_audio(input_file, sample_rate)\n",
    "feat= load_mel.get_spectrogram(y,sr,apply_denoise=False,return_audio=False)\n",
    "\n",
    "load_mel.plot_feature(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec= torch.tensor(feat)\n",
    "spec= spec.permute(1, 0)\n",
    "spec_stacked, pos_enc, attn_mask = preprocessor.process_MAM_data(spec=spec)\n",
    "\n",
    "\n",
    "spec_stacked.shape, pos_enc.shape, attn_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "z= runner.model(spec_stacked, pos_enc, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-volleyball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
